{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1451bd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement diffusers==0.15.2 (from versions: 0.0.1, 0.0.2, 0.0.3, 0.0.4, 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.3.0, 0.4.0, 0.4.1, 0.4.2, 0.5.0, 0.5.1, 0.6.0, 0.7.0, 0.7.1, 0.7.2, 0.8.0, 0.8.1, 0.9.0, 0.10.0, 0.10.1, 0.10.2, 0.11.0, 0.11.1, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.14.0, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.18.2, 0.19.0, 0.19.1, 0.19.2, 0.19.3, 0.20.0, 0.20.1, 0.20.2, 0.21.0, 0.21.1, 0.21.2, 0.21.3, 0.21.4, 0.22.0, 0.22.1, 0.22.2, 0.22.3, 0.23.0, 0.23.1, 0.24.0, 0.25.0, 0.25.1, 0.26.0, 0.26.1, 0.26.2, 0.26.3, 0.27.0, 0.27.1, 0.27.2, 0.28.0, 0.28.1, 0.28.2, 0.29.0, 0.29.1, 0.29.2, 0.30.0, 0.30.1, 0.30.2, 0.30.3, 0.31.0, 0.32.0, 0.32.1, 0.32.2, 0.33.0, 0.33.1, 0.34.0)\n",
      "ERROR: No matching distribution found for diffusers==0.15.2\n",
      "Keyword arguments {'use_auth_token': None} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pipeline loaded successfully\n",
      "⚠️ No styles.csv found, skipping dataset handling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:08<00:00,  8.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Image generated and saved at: ./outputs/lora-fashion\\generated\\sample_output.png\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 1. Install & Import Dependencies\n",
    "# ========================================\n",
    "!pip install diffusers==0.15.2 transformers accelerate datasets peft\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# ========================================\n",
    "# 2. Configuration\n",
    "# ========================================\n",
    "MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n",
    "OUTPUT_DIR = \"./outputs/lora-fashion\"\n",
    "GEN_DIR = os.path.join(OUTPUT_DIR, \"generated\")\n",
    "\n",
    "# Ensure output folders exist\n",
    "os.makedirs(GEN_DIR, exist_ok=True)\n",
    "\n",
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hugging Face Token (use environment variable for safety)\n",
    "HF_TOKEN = os.getenv(\"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\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 3. Load Stable Diffusion Pipeline\n",
    "# ========================================\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    use_auth_token=HF_TOKEN,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ")\n",
    "pipe = pipe.to(device)\n",
    "print(\"✅ Pipeline loaded successfully\")\n",
    "\n",
    "# ========================================\n",
    "# 4. Dataset Handling\n",
    "# ========================================\n",
    "styles_csv = \"./styles.csv\"  # Update path if needed\n",
    "if os.path.exists(styles_csv):\n",
    "    styles = pd.read_csv(styles_csv)\n",
    "    print(f\"Loaded dataset with {len(styles)} entries\")\n",
    "\n",
    "    # Example: split into train/val (if you want for LoRA later)\n",
    "    train_ratio = 0.8\n",
    "    train_size = int(train_ratio * len(styles))\n",
    "    train_df = styles[:train_size]\n",
    "    val_df = styles[train_size:]\n",
    "\n",
    "    train_dir = os.path.join(OUTPUT_DIR, \"train\")\n",
    "    val_dir = os.path.join(OUTPUT_DIR, \"val\")\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "    # Optional: copy images into folders (if dataset includes paths)\n",
    "    if \"id\" in styles.columns:\n",
    "        img_dir = \"./images\"  # Update if your dataset has another path\n",
    "        for idx, row in train_df.iterrows():\n",
    "            src = os.path.join(img_dir, str(row[\"id\"]) + \".jpg\")\n",
    "            dst = os.path.join(train_dir, str(row[\"id\"]) + \".jpg\")\n",
    "            if os.path.exists(src):\n",
    "                shutil.copy(src, dst)\n",
    "\n",
    "        for idx, row in val_df.iterrows():\n",
    "            src = os.path.join(img_dir, str(row[\"id\"]) + \".jpg\")\n",
    "            dst = os.path.join(val_dir, str(row[\"id\"]) + \".jpg\")\n",
    "            if os.path.exists(src):\n",
    "                shutil.copy(src, dst)\n",
    "    print(\"✅ Dataset split into train/val folders\")\n",
    "else:\n",
    "    print(\"⚠️ No styles.csv found, skipping dataset handling\")\n",
    "\n",
    "# ========================================\n",
    "# 5. Generate a Test Image\n",
    "# ========================================\n",
    "prompt = \"A stylish modern outfit for men, streetwear fashion\"\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "# Save to structured output folder\n",
    "output_path = os.path.join(GEN_DIR, \"sample_output.png\")\n",
    "image.save(output_path)\n",
    "\n",
    "print(f\"🎉 Image generated and saved at: {output_path}\")\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e2d1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ fashion_captions.csv created at: C:\\Users\\ACER\\Downloads\\archive (25)\\fashion_captions.csv\n",
      "Total training samples: 44419\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Base folder\n",
    "base_path = r\"C:\\Users\\ACER\\Downloads\\archive (25)\"\n",
    "\n",
    "# Load styles.csv\n",
    "styles = pd.read_csv(os.path.join(base_path, \"styles.csv\"), on_bad_lines=\"skip\")\n",
    "\n",
    "# Construct captions\n",
    "styles[\"caption\"] = (\n",
    "    styles[\"baseColour\"].fillna(\"\") + \" \" +\n",
    "    styles[\"season\"].fillna(\"\") + \" \" +\n",
    "    styles[\"gender\"].fillna(\"\") + \" \" +\n",
    "    styles[\"articleType\"].fillna(\"\") + \" - \" +\n",
    "    styles[\"productDisplayName\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "# Create image path column\n",
    "img_folder = os.path.join(base_path, \"images\")\n",
    "styles[\"image_path\"] = styles[\"id\"].astype(str) + \".jpg\"\n",
    "styles[\"image_path\"] = styles[\"image_path\"].apply(lambda x: os.path.join(img_folder, x))\n",
    "\n",
    "# Keep only rows where the image exists\n",
    "styles = styles[styles[\"image_path\"].apply(os.path.exists)]\n",
    "\n",
    "# Save new training metadata\n",
    "output_file = os.path.join(base_path, \"fashion_captions.csv\")\n",
    "styles[[\"image_path\", \"caption\"]].to_csv(output_file, index=False)\n",
    "\n",
    "print(\"✅ fashion_captions.csv created at:\", output_file)\n",
    "print(\"Total training samples:\", len(styles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98ad6652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44424, 10)\n",
      "      id gender masterCategory subCategory  articleType baseColour  season  \\\n",
      "0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n",
      "1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n",
      "2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n",
      "3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n",
      "4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n",
      "\n",
      "     year   usage                             productDisplayName  \n",
      "0  2011.0  Casual               Turtle Check Men Navy Blue Shirt  \n",
      "1  2012.0  Casual             Peter England Men Party Blue Jeans  \n",
      "2  2016.0  Casual                       Titan Women Silver Watch  \n",
      "3  2011.0  Casual  Manchester United Men Solid Black Track Pants  \n",
      "4  2012.0  Casual                          Puma Men Grey T-shirt  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metadata_path = r\"C:\\Users\\ACER\\Downloads\\archive (25)\\styles.csv\"\n",
    "\n",
    "# Skip malformed rows\n",
    "df = pd.read_csv(metadata_path, on_bad_lines=\"skip\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da5891fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad rows: [6044, 6569, 7399, 7939, 9026, 10264, 10427, 10905, 11373, 11945, 14112, 14532, 15076, 29906, 31625, 33020, 35748, 35962, 37770, 38105]\n"
     ]
    }
   ],
   "source": [
    "bad_rows = []\n",
    "with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f, start=1):\n",
    "        if line.count(\",\") != 9:   # expecting 10 fields\n",
    "            bad_rows.append(i)\n",
    "\n",
    "print(\"Bad rows:\", bad_rows[:20])  # first 20 bad rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67636234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(metadata_path, encoding=\"utf-8\", quotechar='\"', on_bad_lines=\"skip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ed03995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44417, 10)\n",
      "      id gender masterCategory subCategory articleType baseColour  season  \\\n",
      "0  15970    Men        Apparel     Topwear      Shirts  Navy Blue    Fall   \n",
      "1  39386    Men        Apparel  Bottomwear       Jeans       Blue  Summer   \n",
      "2  59263  Women    Accessories     Watches     Watches     Silver  Winter   \n",
      "\n",
      "     year   usage                  productDisplayName  \n",
      "0  2011.0  Casual    Turtle Check Men Navy Blue Shirt  \n",
      "1  2012.0  Casual  Peter England Men Party Blue Jeans  \n",
      "2  2016.0  Casual            Titan Women Silver Watch  \n"
     ]
    }
   ],
   "source": [
    "# Remove rows with too many missing values\n",
    "df = df.dropna(subset=[\"id\", \"gender\", \"masterCategory\", \"subCategory\", \"articleType\", \"productDisplayName\"])\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "966ff182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset: (44412, 12)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_folder = r\"C:\\Users\\ACER\\Downloads\\archive (25)\\images\"\n",
    "\n",
    "# Keep only rows where image exists\n",
    "df[\"image_path\"] = df[\"id\"].astype(str) + \".jpg\"\n",
    "df[\"image_exists\"] = df[\"image_path\"].apply(lambda x: os.path.exists(os.path.join(image_folder, x)))\n",
    "\n",
    "# Filter valid ones\n",
    "df = df[df[\"image_exists\"]]\n",
    "\n",
    "print(\"Final dataset:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afc594a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                            caption\n",
      "0  15970  Navy Blue Shirts - Turtle Check Men Navy Blue ...\n",
      "1  39386    Blue Jeans - Peter England Men Party Blue Jeans\n",
      "2  59263          Silver Watches - Titan Women Silver Watch\n",
      "3  21379  Black Track Pants - Manchester United Men Soli...\n",
      "4  53759               Grey Tshirts - Puma Men Grey T-shirt\n",
      "5   1855  Grey Tshirts - Inkfruit Mens Chain Reaction T-...\n",
      "6  30805    Green Shirts - Fabindia Men Striped Green Shirt\n",
      "7  26960      Purple Shirts - Jealous 21 Women Purple Shirt\n",
      "8  29114         Navy Blue Socks - Puma Men Pack of 3 Socks\n",
      "9  30039             Black Watches - Skagen Men Black Watch\n"
     ]
    }
   ],
   "source": [
    "df[\"caption\"] = (\n",
    "    df[\"baseColour\"].fillna(\"\") + \" \" +\n",
    "    df[\"articleType\"].fillna(\"\") + \" - \" +\n",
    "    df[\"productDisplayName\"].fillna(\"\")\n",
    ")\n",
    "print(df[[\"id\", \"caption\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dbd8bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned dataset at: C:\\Users\\ACER\\Downloads\\archive (25)\\cleaned_styles.csv\n"
     ]
    }
   ],
   "source": [
    "final_path = r\"C:\\Users\\ACER\\Downloads\\archive (25)\\cleaned_styles.csv\"\n",
    "df.to_csv(final_path, index=False)\n",
    "print(\"Saved cleaned dataset at:\", final_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d7559a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 44412 rows. Generating 8 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Fetching 12 files:  17%|█▋        | 2/12 [00:00<00:01,  5.08it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Fetching 12 files: 100%|██████████| 12/12 [17:57<00:00, 89.81s/it] \n",
      "Loading pipeline components...: 100%|██████████| 5/5 [00:01<00:00,  4.90it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|██████████| 4/4 [00:19<00:00,  4.80s/it]\n",
      "100%|██████████| 4/4 [00:15<00:00,  3.87s/it]\n",
      "100%|██████████| 4/4 [00:15<00:00,  3.86s/it]\n",
      "100%|██████████| 4/4 [00:14<00:00,  3.54s/it]\n",
      "100%|██████████| 4/4 [00:14<00:00,  3.73s/it]\n",
      "100%|██████████| 4/4 [00:16<00:00,  4.02s/it]\n",
      "100%|██████████| 4/4 [00:15<00:00,  3.88s/it]\n",
      "100%|██████████| 4/4 [00:15<00:00,  3.99s/it]\n",
      "100%|██████████| 8/8 [03:20<00:00, 25.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done. Images saved to: C:\\Users\\ACER\\Downloads\\archive (25)\\gen_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Image generation from captions\n",
    "# ================================\n",
    "# Install once (terminal or first cell):\n",
    "# pip install -U diffusers transformers accelerate safetensors\n",
    "\n",
    "import os, random\n",
    "import torch\n",
    "import pandas as pd\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------ config ------------\n",
    "BASE_DIR   = r\"C:\\Users\\ACER\\Downloads\\archive (25)\"\n",
    "CSV_PATH   = os.path.join(BASE_DIR, \"cleaned_styles.csv\")   # from your previous step\n",
    "OUT_DIR    = os.path.join(BASE_DIR, \"gen_images\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Fast model for CPU:\n",
    "MODEL_ID   = \"stabilityai/sd-turbo\"     # quick on CPU (4–6 steps)\n",
    "# For higher quality (slower on CPU), you can switch to:\n",
    "# MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE      = torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
    "\n",
    "# Turbo defaults (fast)\n",
    "NUM_STEPS  = 4           # sd-turbo likes 1–8\n",
    "GUIDANCE   = 0.0         # sd-turbo is trained for CFG-free (0 or 1)\n",
    "SEED       = 42\n",
    "N_SAMPLES  = 8           # how many products to generate (increase later)\n",
    "\n",
    "# v1-5 (if you switch): NUM_STEPS=20, GUIDANCE=7.5\n",
    "\n",
    "# ------------ load data ------------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "if \"caption\" not in df.columns:\n",
    "    # Minimal caption from existing columns if not present\n",
    "    cols = [c for c in [\"baseColour\",\"articleType\",\"productDisplayName\",\"gender\",\"subCategory\"] if c in df.columns]\n",
    "    df[\"caption\"] = df[cols].fillna(\"\").astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "print(f\"Loaded {len(df)} rows. Generating {N_SAMPLES} images...\")\n",
    "\n",
    "# pick a few rows to preview\n",
    "if len(df) <= N_SAMPLES:\n",
    "    sample_df = df.copy()\n",
    "else:\n",
    "    sample_df = df.sample(N_SAMPLES, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "# ------------ load pipeline ------------\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=DTYPE\n",
    ").to(DEVICE)\n",
    "pipe.safety_checker = None  # optional: skip NSFW checker to speed up\n",
    "pipe.enable_attention_slicing()  # reduce RAM on CPU\n",
    "\n",
    "generator = torch.Generator(device=DEVICE).manual_seed(SEED)\n",
    "\n",
    "# optional negative prompt to keep things clean/simple\n",
    "NEG_PROMPT = \"low quality, blurry, text watermark, deformed, extra limbs, duplicate\"\n",
    "\n",
    "# ------------ generate ------------\n",
    "for i, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n",
    "    p = str(row[\"caption\"]).strip()\n",
    "    # add a tiny prompt template to orient the model to fashion product\n",
    "    prompt = f\"studio product photo, e-commerce style, plain background, {p}\"\n",
    "\n",
    "    result = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=NEG_PROMPT,\n",
    "        num_inference_steps=NUM_STEPS,\n",
    "        guidance_scale=GUIDANCE,\n",
    "        generator=generator,\n",
    "        height=512,\n",
    "        width=512,\n",
    "    )\n",
    "    img = result.images[0]\n",
    "\n",
    "    # file name with id if available\n",
    "    fname = f\"{row['id'] if 'id' in row else f'sample_{i}'}_gen.png\"\n",
    "    img.save(os.path.join(OUT_DIR, fname))\n",
    "\n",
    "print(f\"✅ Done. Images saved to: {OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8fe508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:08<00:00,  1.16s/it]\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import gradio as gr\n",
    "\n",
    "# Load the pipeline (use your saved model or any pretrained one)\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def generate_image(prompt):\n",
    "    image = pipe(prompt).images[0]\n",
    "    return image\n",
    "\n",
    "# Gradio UI\n",
    "interface = gr.Interface(\n",
    "    fn=generate_image,\n",
    "    inputs=gr.Textbox(label=\"Enter a caption\", placeholder=\"e.g. white skirt\"),\n",
    "    outputs=gr.Image(label=\"Generated Image\"),\n",
    "    title=\" Image Generator\",\n",
    "    description=\"Type a caption and generate a synthetic image.\"\n",
    ")\n",
    "\n",
    "interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8db19738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gradio\n",
      "  Downloading gradio-5.42.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting anyio<5.0,>=3.0 (from gradio)\n",
      "  Using cached anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Using cached Brotli-1.1.0-cp312-cp312-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Using cached fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-0.6.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.11.1 (from gradio)\n",
      "  Downloading gradio_client-1.11.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Using cached groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting httpx<1.0,>=0.24.1 (from gradio)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gradio) (0.34.4)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gradio) (2.2.0)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.11.2-cp312-cp312-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gradio) (2.3.1)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gradio) (11.3.0)\n",
      "Collecting pydantic<2.12,>=2.0 (from gradio)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.12.9-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Using cached safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Using cached starlette-0.47.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Using cached tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Using cached typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gradio) (4.14.1)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Using cached uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gradio-client==1.11.1->gradio) (2025.3.0)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.11.1->gradio)\n",
      "  Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Collecting sniffio>=1.1 (from anyio<5.0,>=3.0->gradio)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
      "Collecting httpcore==1.* (from httpx<1.0,>=0.24.1->gradio)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
      "Requirement already satisfied: requests in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from typer<1.0,>=0.12->gradio) (14.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
      "Downloading gradio-5.42.0-py3-none-any.whl (59.7 MB)\n",
      "   ---------------------------------------- 0.0/59.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 3.4/59.7 MB 25.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 4.7/59.7 MB 13.0 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 5.8/59.7 MB 9.8 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 6.8/59.7 MB 8.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 7.9/59.7 MB 7.8 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 8.7/59.7 MB 7.5 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 9.2/59.7 MB 6.5 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 9.4/59.7 MB 5.9 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 10.0/59.7 MB 5.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 10.5/59.7 MB 5.0 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 11.0/59.7 MB 4.8 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 11.8/59.7 MB 4.7 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 12.6/59.7 MB 4.7 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 13.6/59.7 MB 4.7 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 14.9/59.7 MB 4.8 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 16.3/59.7 MB 4.9 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 17.6/59.7 MB 5.0 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 19.1/59.7 MB 5.1 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 21.0/59.7 MB 5.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 22.0/59.7 MB 5.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 22.3/59.7 MB 5.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 22.8/59.7 MB 5.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 23.6/59.7 MB 4.9 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 24.4/59.7 MB 4.9 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 25.2/59.7 MB 4.8 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 26.2/59.7 MB 4.9 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 27.3/59.7 MB 4.9 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 28.8/59.7 MB 4.9 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 30.1/59.7 MB 5.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 31.7/59.7 MB 5.1 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 32.5/59.7 MB 5.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 33.0/59.7 MB 5.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 33.6/59.7 MB 4.9 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 34.1/59.7 MB 4.9 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 34.9/59.7 MB 4.8 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 35.7/59.7 MB 4.8 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 36.4/59.7 MB 4.8 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 37.5/59.7 MB 4.8 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 38.8/59.7 MB 4.8 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 40.1/59.7 MB 4.8 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 41.4/59.7 MB 4.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 43.3/59.7 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 44.8/59.7 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 45.6/59.7 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 46.1/59.7 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 46.4/59.7 MB 4.9 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 46.7/59.7 MB 4.9 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 47.4/59.7 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 48.0/59.7 MB 4.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 48.8/59.7 MB 4.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 49.8/59.7 MB 4.7 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 50.9/59.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 51.9/59.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 53.5/59.7 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 54.8/59.7 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 56.4/59.7 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 57.9/59.7 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  58.5/59.7 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  59.0/59.7 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  59.5/59.7 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 59.7/59.7 MB 4.7 MB/s  0:00:12\n",
      "Downloading gradio_client-1.11.1-py3-none-any.whl (324 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Using cached fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Using cached groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading orjson-3.11.2-cp312-cp312-win_amd64.whl (119 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached starlette-0.47.2-py3-none-any.whl (72 kB)\n",
      "Using cached tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached Brotli-1.1.0-cp312-cp312-win_amd64.whl (357 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.12.9-py3-none-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.8 MB 3.4 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.6/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.4/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.7/12.8 MB 4.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.0/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.3/12.8 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.9/12.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.8 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.7/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/12.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.1/12.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.8 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 5.0 MB/s  0:00:02\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Using cached ffmpy-0.6.1-py3-none-any.whl (5.5 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub, brotli, websockets, typing-inspection, tomlkit, sniffio, shellingham, semantic-version, ruff, python-multipart, pydantic-core, orjson, h11, groovy, ffmpy, click, annotated-types, aiofiles, uvicorn, pydantic, httpcore, anyio, typer, starlette, httpx, safehttpx, gradio-client, fastapi, gradio\n",
      "\n",
      "   ----------------------------------------  0/29 [pydub]\n",
      "   - --------------------------------------  1/29 [brotli]\n",
      "   -- -------------------------------------  2/29 [websockets]\n",
      "   -- -------------------------------------  2/29 [websockets]\n",
      "   -- -------------------------------------  2/29 [websockets]\n",
      "   -- -------------------------------------  2/29 [websockets]\n",
      "   -- -------------------------------------  2/29 [websockets]\n",
      "   -- -------------------------------------  2/29 [websockets]\n",
      "   -- -------------------------------------  2/29 [websockets]\n",
      "   -- -------------------------------------  2/29 [websockets]\n",
      "   -- -------------------------------------  2/29 [websockets]\n",
      "   -- -------------------------------------  2/29 [websockets]\n",
      "   -- -------------------------------------  2/29 [websockets]\n",
      "   ---- -----------------------------------  3/29 [typing-inspection]\n",
      "   ----- ----------------------------------  4/29 [tomlkit]\n",
      "   ----- ----------------------------------  4/29 [tomlkit]\n",
      "   ----- ----------------------------------  4/29 [tomlkit]\n",
      "   -------- -------------------------------  6/29 [shellingham]\n",
      "   -------- -------------------------------  6/29 [shellingham]\n",
      "   ----------- ----------------------------  8/29 [ruff]\n",
      "   ----------- ----------------------------  8/29 [ruff]\n",
      "   ----------- ----------------------------  8/29 [ruff]\n",
      "   ----------- ----------------------------  8/29 [ruff]\n",
      "   ----------- ----------------------------  8/29 [ruff]\n",
      "   ----------- ----------------------------  8/29 [ruff]\n",
      "   ----------- ----------------------------  8/29 [ruff]\n",
      "   ----------- ----------------------------  8/29 [ruff]\n",
      "   ----------- ----------------------------  8/29 [ruff]\n",
      "   ----------- ----------------------------  8/29 [ruff]\n",
      "   ------------ ---------------------------  9/29 [python-multipart]\n",
      "   ------------- -------------------------- 10/29 [pydantic-core]\n",
      "   ---------------- ----------------------- 12/29 [h11]\n",
      "   ---------------- ----------------------- 12/29 [h11]\n",
      "   ---------------- ----------------------- 12/29 [h11]\n",
      "   ---------------- ----------------------- 12/29 [h11]\n",
      "   ------------------- -------------------- 14/29 [ffmpy]\n",
      "   -------------------- ------------------- 15/29 [click]\n",
      "   -------------------- ------------------- 15/29 [click]\n",
      "   -------------------- ------------------- 15/29 [click]\n",
      "   ---------------------- ----------------- 16/29 [annotated-types]\n",
      "   ----------------------- ---------------- 17/29 [aiofiles]\n",
      "   ------------------------ --------------- 18/29 [uvicorn]\n",
      "   ------------------------ --------------- 18/29 [uvicorn]\n",
      "   ------------------------ --------------- 18/29 [uvicorn]\n",
      "   ------------------------ --------------- 18/29 [uvicorn]\n",
      "   ------------------------ --------------- 18/29 [uvicorn]\n",
      "   ------------------------ --------------- 18/29 [uvicorn]\n",
      "   ------------------------ --------------- 18/29 [uvicorn]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   -------------------------- ------------- 19/29 [pydantic]\n",
      "   --------------------------- ------------ 20/29 [httpcore]\n",
      "   --------------------------- ------------ 20/29 [httpcore]\n",
      "   --------------------------- ------------ 20/29 [httpcore]\n",
      "   --------------------------- ------------ 20/29 [httpcore]\n",
      "   --------------------------- ------------ 20/29 [httpcore]\n",
      "   --------------------------- ------------ 20/29 [httpcore]\n",
      "   ---------------------------- ----------- 21/29 [anyio]\n",
      "   ---------------------------- ----------- 21/29 [anyio]\n",
      "   ---------------------------- ----------- 21/29 [anyio]\n",
      "   ---------------------------- ----------- 21/29 [anyio]\n",
      "   ---------------------------- ----------- 21/29 [anyio]\n",
      "   ---------------------------- ----------- 21/29 [anyio]\n",
      "   ---------------------------- ----------- 21/29 [anyio]\n",
      "   ------------------------------ --------- 22/29 [typer]\n",
      "   ------------------------------ --------- 22/29 [typer]\n",
      "   ------------------------------ --------- 22/29 [typer]\n",
      "   ------------------------------ --------- 22/29 [typer]\n",
      "   ------------------------------- -------- 23/29 [starlette]\n",
      "   ------------------------------- -------- 23/29 [starlette]\n",
      "   ------------------------------- -------- 23/29 [starlette]\n",
      "   ------------------------------- -------- 23/29 [starlette]\n",
      "   ------------------------------- -------- 23/29 [starlette]\n",
      "   ------------------------------- -------- 23/29 [starlette]\n",
      "   ------------------------------- -------- 23/29 [starlette]\n",
      "   --------------------------------- ------ 24/29 [httpx]\n",
      "   --------------------------------- ------ 24/29 [httpx]\n",
      "   --------------------------------- ------ 24/29 [httpx]\n",
      "   --------------------------------- ------ 24/29 [httpx]\n",
      "   --------------------------------- ------ 24/29 [httpx]\n",
      "   --------------------------------- ------ 24/29 [httpx]\n",
      "   ---------------------------------- ----- 25/29 [safehttpx]\n",
      "   ----------------------------------- ---- 26/29 [gradio-client]\n",
      "   ----------------------------------- ---- 26/29 [gradio-client]\n",
      "   ------------------------------------- -- 27/29 [fastapi]\n",
      "   ------------------------------------- -- 27/29 [fastapi]\n",
      "   ------------------------------------- -- 27/29 [fastapi]\n",
      "   ------------------------------------- -- 27/29 [fastapi]\n",
      "   ------------------------------------- -- 27/29 [fastapi]\n",
      "   ------------------------------------- -- 27/29 [fastapi]\n",
      "   ------------------------------------- -- 27/29 [fastapi]\n",
      "   ------------------------------------- -- 27/29 [fastapi]\n",
      "   ------------------------------------- -- 27/29 [fastapi]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   -------------------------------------- - 28/29 [gradio]\n",
      "   ---------------------------------------- 29/29 [gradio]\n",
      "\n",
      "Successfully installed aiofiles-24.1.0 annotated-types-0.7.0 anyio-4.10.0 brotli-1.1.0 click-8.2.1 fastapi-0.116.1 ffmpy-0.6.1 gradio-5.42.0 gradio-client-1.11.1 groovy-0.1.2 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 orjson-3.11.2 pydantic-2.11.7 pydantic-core-2.33.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.12.9 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.47.2 tomlkit-0.13.3 typer-0.16.0 typing-inspection-0.4.1 uvicorn-0.35.0 websockets-15.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
